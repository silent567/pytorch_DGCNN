{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-5:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "sys.argv = ['main.py']\n",
    "import argparse\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "from my_main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-save_model'], dest='save_model', nargs=None, const=None, default=False, type=<class 'bool'>, choices=None, help='For Saving the current Model', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cmd_opt = argparse.ArgumentParser(description='Argparser for graph_classification')\n",
    "cmd_opt.add_argument('-mode', default='cpu', help='cpu/gpu')\n",
    "cmd_opt.add_argument('-gm', default='mean_field', help='mean_field/loopy_bp')\n",
    "cmd_opt.add_argument('-data', default=None, help='data folder name')\n",
    "cmd_opt.add_argument('-batch_size', type=int, default=50, help='minibatch size')\n",
    "cmd_opt.add_argument('-seed', type=int, default=1, help='seed')\n",
    "cmd_opt.add_argument('-feat_dim', type=int, default=0, help='dimension of discrete node feature (maximum node tag)')\n",
    "cmd_opt.add_argument('-num_class', type=int, default=0, help='#classes')\n",
    "cmd_opt.add_argument('-fold', type=int, default=1, help='fold (1..10)')\n",
    "cmd_opt.add_argument('-test_number', type=int, default=0, help='if specified, will overwrite -fold and use the last -test_number graphs as testing data')\n",
    "cmd_opt.add_argument('-num_epochs', type=int, default=1000, help='number of epochs')\n",
    "cmd_opt.add_argument('-latent_dim', type=str, default='32-32-32-1', help='dimension(s) of latent layers')\n",
    "cmd_opt.add_argument('-sortpooling_k', type=float, default=30, help='number of nodes kept after SortPooling')\n",
    "cmd_opt.add_argument('-out_dim', type=int, default=0, help='s2v output size')\n",
    "cmd_opt.add_argument('-hidden', type=int, default=128, help='dimension of regression')\n",
    "cmd_opt.add_argument('-max_lv', type=int, default=4, help='max rounds of message passing')\n",
    "cmd_opt.add_argument('-learning_rate', type=float, default=0.0001, help='init learning_rate')\n",
    "cmd_opt.add_argument('-dropout', type=bool, default=True, help='whether add dropout after dense layer')\n",
    "cmd_opt.add_argument('-printAUC', type=bool, default=False, help='whether to print AUC (for binary classification only)')\n",
    "cmd_opt.add_argument('-extract_features', type=bool, default=False, help='whether to extract final graph features')\n",
    "\n",
    "cmd_opt.add_argument('-gamma', type=float, default=10.0, help='gamma controlling the sparsity of gfusedmax\\'s output (the smaller, the sparser)')\n",
    "cmd_opt.add_argument('-lam', type=float, default=1.0, help='lambda controlling the smoothness of gfusedmax\\'s output (the larger, the smoother)')\n",
    "cmd_opt.add_argument('-norm_flag', type=bool, default=True, help='whether add layer norm layer before gfusedmax')\n",
    "cmd_opt.add_argument('-max_type', default='gfusedmax', choices=['softmax','sparsemax','gfusedmax'], help='mapping function utilized in attentional pooling')\n",
    "cmd_opt.add_argument('-layer_number', type=int, default=3, help='layer number of final MLP')\n",
    "cmd_opt.add_argument('-batch_norm_flag', type=bool, default=True, help='whether add batch norm layer for final MLP')\n",
    "cmd_opt.add_argument('-residual_flag', type=bool, default=True, help='whether utilize residual connection for final MLP')\n",
    "cmd_opt.add_argument('-gnn_batch_norm_flag', type=bool, default=True, help='whether add batch norm layer for GNN\\'s output')\n",
    "cmd_opt.add_argument('-l2', type=float, default=1e-3, help='l2 controlling the regularization strength')\n",
    "cmd_opt.add_argument('-head_cnt', type=int, default=2, help='Number of parallel attentional aggregators')\n",
    "\n",
    "cmd_opt.add_argument('-save_model', type=bool, default=False, help='For Saving the current Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_args, _ = cmd_opt.parse_known_args('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_norm_flag=True, batch_size=50, data='COMP', dropout=True, extract_features=False, feat_dim=0, fold=1, gamma=10.0, gm='FastMultiAttPool', gnn_batch_norm_flag=True, head_cnt=2, hidden=128, l2=0, lam=1.0, latent_dim=[32, 32, 32, 1], layer_number=3, learning_rate=0.001, max_lv=4, max_type='gfusedmax', mode='cpu', norm_flag=1.0, num_class=0, num_epochs=1000, out_dim=0, printAUC=False, residual_flag=True, save_model=False, seed=1, sortpooling_k=30, test_number=0)\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_FastMultiAttPool_COMP_gfusedmax_1_10.00_1.00.pt'\n",
    "params = model_name.strip('.pt').split('_')\n",
    "cmd_args.l2 = 0\n",
    "cmd_args.learning_rate = 1e-3\n",
    "cmd_args.latent_dim = [32,32,32,1]\n",
    "cmd_args.lam = float(params[-1])\n",
    "cmd_args.gamma = float(params[-2])\n",
    "cmd_args.norm_flag = float(params[-3])\n",
    "cmd_args.max_type = params[-4]\n",
    "cmd_args.data = params[-5]\n",
    "cmd_args.gm = params[-6]\n",
    "print(cmd_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "# classes: 11\n",
      "# maximum node tag: 1\n",
      "# train: 900, # test: 100\n",
      "Namespace(attr_dim=0, batch_norm_flag=True, batch_size=50, data='COMPsmall', dropout=True, extract_features=False, feat_dim=1, fold=1, gamma=10.0, gm='FastMultiAttPool', gnn_batch_norm_flag=True, head_cnt=2, hidden=128, l2=0, lam=1.0, latent_dim=[32, 32, 32, 1], layer_number=3, learning_rate=0.001, max_lv=4, max_type='gfusedmax', mode='cpu', norm_flag=1.0, num_class=11, num_epochs=1000, out_dim=0, printAUC=False, residual_flag=True, save_model=False, seed=1, sortpooling_k=30, test_number=0)\n"
     ]
    }
   ],
   "source": [
    "cmd_args.data = 'COMPsmall'\n",
    "os.chdir('/root/dgcnn')\n",
    "train_graphs, test_graphs = load_data(cmd_args)\n",
    "print('# train: %d, # test: %d' % (len(train_graphs), len(test_graphs)))\n",
    "print(cmd_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cmd_args.sortpooling_k <= 1:\n",
    "    num_nodes_list = sorted([g.num_nodes for g in train_graphs + test_graphs])\n",
    "    cmd_args.sortpooling_k = num_nodes_list[int(math.ceil(cmd_args.sortpooling_k * len(num_nodes_list))) - 1]\n",
    "    cmd_args.sortpooling_k = max(10, cmd_args.sortpooling_k)\n",
    "    print('k used in SortPooling is: ' + str(cmd_args.sortpooling_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attr_dim=0, batch_norm_flag=True, batch_size=50, data='COMPsmall', dropout=True, extract_features=False, feat_dim=1, fold=1, gamma=10.0, gm='FastMultiAttPool', gnn_batch_norm_flag=True, head_cnt=2, hidden=128, l2=0, lam=1.0, latent_dim=[32, 32, 32, 1], layer_number=3, learning_rate=0.001, max_lv=4, max_type='gfusedmax', mode='cpu', norm_flag=1.0, num_class=11, num_epochs=1000, out_dim=0, printAUC=False, residual_flag=True, save_model=False, seed=1, sortpooling_k=30, test_number=0)\n",
      "Initializing AttPool\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(cmd_args)\n",
    "model = Classifier(cmd_args)\n",
    "model.load_state_dict(torch.load(model_name,map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-16fbe259045a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnode_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mnode_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyPrepareFeatureLabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_graph' is not defined"
     ]
    }
   ],
   "source": [
    "def myPrepareFeatureLabel(batch_graph,):\n",
    "    labels = torch.LongTensor(len(batch_graph))\n",
    "    n_nodes = 0\n",
    "\n",
    "    if batch_graph[0].node_tags is not None:\n",
    "        node_tag_flag = True\n",
    "        concat_tag = []\n",
    "    else:\n",
    "        node_tag_flag = False\n",
    "\n",
    "    if batch_graph[0].node_features is not None:\n",
    "        node_feat_flag = True\n",
    "        concat_feat = []\n",
    "    else:\n",
    "        node_feat_flag = False\n",
    "\n",
    "    for i in range(len(batch_graph)):\n",
    "        labels[i] = batch_graph[i].label\n",
    "        n_nodes += batch_graph[i].num_nodes\n",
    "        if node_tag_flag == True:\n",
    "            concat_tag += batch_graph[i].node_tags\n",
    "        if node_feat_flag == True:\n",
    "            tmp = torch.from_numpy(batch_graph[i].node_features).type('torch.FloatTensor')\n",
    "            concat_feat.append(tmp)\n",
    "\n",
    "    if node_tag_flag == True:\n",
    "        concat_tag = torch.LongTensor(concat_tag).view(-1, 1)\n",
    "        node_tag = torch.zeros(n_nodes, cmd_args.feat_dim)\n",
    "        node_tag.scatter_(1, concat_tag, 1)\n",
    "\n",
    "    if node_feat_flag == True:\n",
    "        node_feat = torch.cat(concat_feat, 0)\n",
    "\n",
    "    if node_feat_flag and node_tag_flag:\n",
    "        # concatenate one-hot embedding of node tags (node labels) with continuous node features\n",
    "        node_feat = torch.cat([node_tag.type_as(node_feat), node_feat], 1)\n",
    "    elif node_feat_flag == False and node_tag_flag == True:\n",
    "        node_feat = node_tag\n",
    "    elif node_feat_flag == True and node_tag_flag == False:\n",
    "        pass\n",
    "    else:\n",
    "        node_feat = torch.ones(n_nodes, 1)  # use all-one vector as node features\n",
    "\n",
    "    if cmd_args.mode == 'gpu':\n",
    "        node_feat = node_feat.cuda()\n",
    "        labels = labels.cuda()\n",
    "    return node_feat, labels\n",
    "node_feat, labels = myPrepareFeatureLabel(batch_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_embedding import *\n",
    "def myS2V(s2v,graph_list,node_feat,edge_feat):\n",
    "    graph_sizes = [graph_list[i].num_nodes for i in range(len(graph_list))]\n",
    "    node_degs = [torch.Tensor(graph_list[i].degs) + 1 for i in range(len(graph_list))]\n",
    "    node_degs = torch.cat(node_degs).unsqueeze(1)\n",
    "\n",
    "    n2n_sp, e2n_sp, subg_sp = S2VLIB.PrepareMeanField(graph_list)\n",
    "\n",
    "    if 'cuda' in str(node_feat.device):\n",
    "        n2n_sp = n2n_sp.cuda()\n",
    "        e2n_sp = e2n_sp.cuda()\n",
    "        subg_sp = subg_sp.cuda()\n",
    "        node_degs = node_degs.cuda()\n",
    "    node_feat = Variable(node_feat)\n",
    "    if edge_feat is not None:\n",
    "        edge_feat = Variable(edge_feat)\n",
    "    n2n_sp = Variable(n2n_sp)\n",
    "    e2n_sp = Variable(e2n_sp)\n",
    "    subg_sp = Variable(subg_sp)\n",
    "    node_degs = Variable(node_degs)\n",
    "\n",
    "    if edge_feat is not None:\n",
    "        input_edge_linear = s2v.w_e2l(edge_feat)\n",
    "        e2npool_input = gnn_spmm(e2n_sp, input_edge_linear)\n",
    "        node_feat = torch.cat([node_feat, e2npool_input], 1)\n",
    "\n",
    "    ''' graph convolution layers '''\n",
    "    lv = 0\n",
    "    cur_message_layer = node_feat\n",
    "    cat_message_layers = []\n",
    "    while lv < len(s2v.latent_dim):\n",
    "        n2npool = gnn_spmm(n2n_sp, cur_message_layer) + cur_message_layer  # Y = (A + I) * X\n",
    "        node_linear = s2v.conv_params[lv](n2npool)  # Y = Y * W\n",
    "        normalized_linear = node_linear.div(node_degs)  # Y = D^-1 * Y\n",
    "        cur_message_layer = F.tanh(normalized_linear)\n",
    "        cat_message_layers.append(cur_message_layer)\n",
    "        lv += 1\n",
    "\n",
    "    cur_message_layer = torch.cat(cat_message_layers, 1)\n",
    "    cur_message_layer = s2v.batch_norm(cur_message_layer)\n",
    "\n",
    "    graph_size_cumsum = [0,] + list(np.cumsum(graph_sizes).astype('int'))\n",
    "\n",
    "    '''Attentional pooling'''\n",
    "    edge_list = [build_edges(graph_list[i])for i in range(len(graph_sizes))]\n",
    "    to_dense = torch.cat([att_aggr([cur_message_layer[graph_size_cumsum[i]:graph_size_cumsum[i+1]] for i in range(len(graph_sizes))]\n",
    "                              ,[build_edges(graph_list[i]) for i in range(len(graph_sizes))]) for att_aggr in s2v.att_aggrs], dim=-1)\n",
    "\n",
    "    if s2v.output_dim > 0:\n",
    "        out_linear = s2v.out_params(to_dense)\n",
    "        reluact_fp = F.relu(out_linear)\n",
    "    else:\n",
    "        reluact_fp = to_dense\n",
    "\n",
    "    embed = F.relu(reluact_fp)\n",
    "    return embed\n",
    "embed = myS2V(model.s2v,batch_graph,node_feat,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_attention import *\n",
    "from my_embedding import *\n",
    "def myAttPool(att,x_list,edge_list,q=None):\n",
    "    '''\n",
    "    x's shape = [M,C]*N\n",
    "    edge_list's shape = [[M,2]]*N\n",
    "    q's shape = [C']*N\n",
    "    return y's shape = [N,C'']\n",
    "    '''\n",
    "    N = len(x_list)\n",
    "    M_list = [x.size()[0] for x in x_list]\n",
    "    M_cumsum = [0,]+list(np.cumsum(M_list))\n",
    "    output_list = [None]*N\n",
    "    for i,m in enumerate(M_list):\n",
    "        if m == 0:\n",
    "            output_list[i] = torch.zeros([att.output_size],dtype=x_list[i].dtype,device=x_list[i].device)\n",
    "\n",
    "    x_concat = torch.cat(x_list,dim=0) #[N*M,C]\n",
    "    proj_x = att.proj_func(x_concat) #[N*M,C'']\n",
    "    for i,(m,ms) in enumerate(zip(M_list,M_cumsum)):\n",
    "        if m == 1:\n",
    "            output_list[i] = proj_x[ms]\n",
    "    score_x = att.score_func(x_concat if att.query_size < 1 else torch.cat(\n",
    "        [x_concat,torch.stack([qq for m,qq in zip(M_list,q) for _ in range(m)],dim=0)],dim=-1)) #[N*M,1]\n",
    "\n",
    "    cuda_flag = score_x.is_cuda\n",
    "    if cuda_flag:\n",
    "        score_x = score_x.cpu()\n",
    "    score_x = score_x.squeeze() #[N*M]\n",
    "    weight_list = att.mapping_func(score_x,edge_list,M_cumsum) #[M]*N\n",
    "    if cuda_flag:\n",
    "        for i,w in enumerate(weight_list):\n",
    "            weight_list[i] = w.cuda()\n",
    "\n",
    "    for i,w in enumerate(weight_list):\n",
    "        if w.size()[0] > 1:\n",
    "            output_list[i] = torch.sum(proj_x[M_cumsum[i]:M_cumsum[i+1]]*w.unsqueeze(-1),dim=0)\n",
    "    output = torch.stack(output_list,dim=0)\n",
    "    return output, weight_list\n",
    "def myS2V_with_weight(s2v,graph_list,node_feat,edge_feat):\n",
    "    graph_sizes = [graph_list[i].num_nodes for i in range(len(graph_list))]\n",
    "    node_degs = [torch.Tensor(graph_list[i].degs) + 1 for i in range(len(graph_list))]\n",
    "    node_degs = torch.cat(node_degs).unsqueeze(1)\n",
    "\n",
    "    n2n_sp, e2n_sp, subg_sp = S2VLIB.PrepareMeanField(graph_list)\n",
    "\n",
    "    if 'cuda' in str(node_feat.device):\n",
    "        n2n_sp = n2n_sp.cuda()\n",
    "        e2n_sp = e2n_sp.cuda()\n",
    "        subg_sp = subg_sp.cuda()\n",
    "        node_degs = node_degs.cuda()\n",
    "    node_feat = Variable(node_feat)\n",
    "    if edge_feat is not None:\n",
    "        edge_feat = Variable(edge_feat)\n",
    "    n2n_sp = Variable(n2n_sp)\n",
    "    e2n_sp = Variable(e2n_sp)\n",
    "    subg_sp = Variable(subg_sp)\n",
    "    node_degs = Variable(node_degs)\n",
    "\n",
    "    if edge_feat is not None:\n",
    "        input_edge_linear = s2v.w_e2l(edge_feat)\n",
    "        e2npool_input = gnn_spmm(e2n_sp, input_edge_linear)\n",
    "        node_feat = torch.cat([node_feat, e2npool_input], 1)\n",
    "\n",
    "    ''' graph convolution layers '''\n",
    "    lv = 0\n",
    "    cur_message_layer = node_feat\n",
    "    cat_message_layers = []\n",
    "    while lv < len(s2v.latent_dim):\n",
    "        n2npool = gnn_spmm(n2n_sp, cur_message_layer) + cur_message_layer  # Y = (A + I) * X\n",
    "        node_linear = s2v.conv_params[lv](n2npool)  # Y = Y * W\n",
    "        normalized_linear = node_linear.div(node_degs)  # Y = D^-1 * Y\n",
    "        cur_message_layer = F.tanh(normalized_linear)\n",
    "        cat_message_layers.append(cur_message_layer)\n",
    "        lv += 1\n",
    "\n",
    "    cur_message_layer = torch.cat(cat_message_layers, 1)\n",
    "    cur_message_layer = s2v.batch_norm(cur_message_layer)\n",
    "\n",
    "    graph_size_cumsum = [0,] + list(np.cumsum(graph_sizes).astype('int'))\n",
    "\n",
    "    '''Attentional pooling'''\n",
    "    edge_list = [build_edges(graph_list[i])for i in range(len(graph_sizes))]\n",
    "    att_aggr_output = []\n",
    "    att_aggr_weights = []\n",
    "    for att_aggr in s2v.att_aggrs:\n",
    "        tmp_output,tmp_weight = myAttPool(att_aggr,[cur_message_layer[graph_size_cumsum[i]:graph_size_cumsum[i+1]] for i in range(len(graph_sizes))],edge_list)\n",
    "        att_aggr_output.append(tmp_output)\n",
    "        att_aggr_weights.append(tmp_weight)\n",
    "                                                                                                                                                    \n",
    "    to_dense = torch.cat(att_aggr_output, dim=-1)\n",
    "\n",
    "    if s2v.output_dim > 0:\n",
    "        out_linear = s2v.out_params(to_dense)\n",
    "        reluact_fp = F.relu(out_linear)\n",
    "    else:\n",
    "        reluact_fp = to_dense\n",
    "\n",
    "    embed = F.relu(reluact_fp)\n",
    "    return embed, att_aggr_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-02aa96cec453>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnode_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyPrepareFeatureLabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0membed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyS2V_with_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms2v\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-6da2379e11f6>\u001b[0m in \u001b[0;36mmyS2V_with_weight\u001b[0;34m(s2v, graph_list, node_feat, edge_feat)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0matt_aggr_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0matt_aggr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matt_aggrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mtmp_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtmp_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyAttPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matt_aggr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_message_layer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgraph_size_cumsum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mgraph_size_cumsum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0matt_aggr_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0matt_aggr_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-6da2379e11f6>\u001b[0m in \u001b[0;36mmyAttPool\u001b[0;34m(att, x_list, edge_list, q)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mscore_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mscore_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#[N*M]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mweight_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM_cumsum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#[M]*N\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcuda_flag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dgcnn/torch_attention.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, graph_list, M_cumsum)\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;31m# self.gfusedmax_module = Gfusedmax3(self.gamma,self.lam)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfusedmax_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGfusedmaxList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgraph_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM_cumsum\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfusedmax_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgraph_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM_cumsum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Wrong max_type: %s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mmax_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dgcnn/env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dgcnn/torch_mapping.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_list, M_cumsum)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         '''\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mfused_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfusedlasso_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM_cumsum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparsemax_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfused_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mM_cumsum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mM_cumsum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_cumsum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dgcnn/torch_mapping.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, edge_list, M_cumsum)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGfusedmaxList\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfusedlasso_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM_cumsum\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch_gfusedlasso_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM_cumsum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparsemax_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch_sparsemax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM_cumsum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dgcnn/torch_mapping.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, inp, edge_list, M_cumsum, lam)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#[N*M]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0minp_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mM_cumsum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mM_cumsum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_cumsum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#[M]*N\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0moutput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgfusedlasso_with_edge\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#[M]*N\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#[N*M]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mstarmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mbecomes\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         '''\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     def starmap_async(self, func, iterable, chunksize=None, callback=None,\n",
      "\u001b[0;32m/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/pyenv/versions/3.6.5/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/pyenv/versions/3.6.5/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/pyenv/versions/3.6.5/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "index = np.random.choice(len(test_graphs),50)\n",
    "batch_graph = [test_graphs[i] for i in index]\n",
    "true_labels = [g.label for g in batch_graph]\n",
    "\n",
    "model.eval()\n",
    "node_feat, labels = myPrepareFeatureLabel(batch_graph)\n",
    "embed,weights = myS2V_with_weight(model.s2v,batch_graph, node_feat, None)\n",
    "logits, loss, acc =  model.mlp(embed, labels)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(graph):\n",
    "    output = np.zeros([graph.num_nodes,graph.num_nodes])\n",
    "    for en in range(graph.num_edges):\n",
    "        i,j = graph.edge_pairs[2*en],graph.edge_pairs[2*en+1]\n",
    "        output[i,j] = output[j,i] = 1\n",
    "    return output\n",
    "def to_nx_graph(g):\n",
    "    return nx.from_numpy_array(build_graph(g))\n",
    "def random_node(g):\n",
    "    nodes = list(g.node)\n",
    "    return np.random.choice(nodes)\n",
    "def plot_graph(g,node_labels=None):\n",
    "    if node_labels is None:\n",
    "        if 'comm' in g.nodes(data=True)[random_node(g)]:\n",
    "            node_labels = [v['comm'] for _,v in g.nodes(data=True)]\n",
    "        else:\n",
    "            node_labels = np.zeros(len(g.nodes))\n",
    "    pos = nx.circular_layout(g)\n",
    "    if 'pos' in g.nodes(data=True)[random_node(g)]:\n",
    "        pos = {n:v['pos'] for n,v in g.nodes(data=True)}\n",
    "\n",
    "    label_set = list(set(node_labels))\n",
    "    label_set.sort()\n",
    "    label2index = {nl:i for i,nl in enumerate(label_set)}\n",
    "    node_labels = [label2index[nl] for nl in node_labels]\n",
    "    nx.draw(g,pos=pos,node_color=node_labels)\n",
    "\n",
    "def plot_adjacency_matrix(graph,node_labels=None):\n",
    "    if node_labels is None:\n",
    "        node_labels = np.zeros(graph.shape[0])\n",
    "    else:\n",
    "        label_set = list(set(node_labels))\n",
    "        label_set.sort()\n",
    "        label2index = {nl:i for i,nl in enumerate(label_set)}\n",
    "        node_labels = [label2index[nl] for nl in node_labels]\n",
    "    g = nx.from_numpy_array(graph)\n",
    "    nx.draw(g,pos=nx.circular_layout(g),node_color=node_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = ['barbell','circular_ladder','complete','cycle','hypercube','shrinking_tree','tree','tri_lattice','turan']\n",
    "pattern2index = {p:i for i,p in enumerate(patterns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Namespace(attr_dim=0, batch_norm_flag=True, batch_size=50, \n",
    "    data='CPnew', dropout=True, extract_features=False, \n",
    "    feat_dim=1, fold=1, gamma=10.0, gm='FastMultiAttPool', \n",
    "    gnn_batch_norm_flag=True, head_cnt=2, hidden=128, l2=0, \n",
    "    lam=1.0, latent_dim=[32, 32, 32, 1], layer_number=3, \n",
    "    learning_rate=0.001, max_lv=4, max_type='gfusedmax', \n",
    "    mode='cpu', norm_flag=1.0, num_class=9, num_epochs=1000, \n",
    "    out_dim=0, printAUC=False, residual_flag=True, s\n",
    "    ave_model=False, seed=1, sortpooling_k=30, test_number=0)\n",
    "'''\n",
    "\n",
    "def reset_cmd_args():\n",
    "    cmd_args.attr_dim = 0\n",
    "    cmd_args.batch_norm_flag=True\n",
    "    cmd_args.batch_size=50\n",
    "    cmd_args.data='CPnew'\n",
    "    cmd_args.dropout=True\n",
    "    cmd_args.extract_features=False\n",
    "    cmd_args.feat_dim=1\n",
    "    cmd_args.fold=1\n",
    "    cmd_args.gamma=10.0\n",
    "    cmd_args.gm='FastMultiAttPool'\n",
    "    cmd_args.gnn_batch_norm_flag=True\n",
    "    cmd_args.head_cnt=2\n",
    "    cmd_args.hidden=128\n",
    "    cmd_args.l2=0\n",
    "    cmd_args.lam=1.0\n",
    "    cmd_args.latent_dim=[32, 32, 32, 1]\n",
    "    cmd_args.layer_number=3\n",
    "    cmd_args.learning_rate=0.001\n",
    "    cmd_args.max_lv=4\n",
    "    cmd_args.max_type='gfusedmax'\n",
    "    cmd_args.mode='cpu'\n",
    "    cmd_args.norm_flag=1.0\n",
    "    cmd_args.num_class=9\n",
    "    cmd_args.num_epochs=1000\n",
    "    cmd_args.out_dim=0\n",
    "    cmd_args.printAUC=False\n",
    "    cmd_args.residual_flag=True\n",
    "    cmd_args.save_model=False, \n",
    "    cmd_args.seed=1\n",
    "    cmd_args.sortpooling_k=30\n",
    "    cmd_args.test_number=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reset_cmd_args()\n",
    "model.eval()\n",
    "index = np.random.choice(len(test_graphs))\n",
    "batch_graph = [test_graphs[index]]\n",
    "true_labels = [g.label for g in batch_graph]\n",
    "\n",
    "node_feat, labels = myPrepareFeatureLabel(batch_graph)\n",
    "embed,weights = myS2V_with_weight(model.s2v,batch_graph, node_feat, None)\n",
    "logits, loss, acc =  model.mlp(embed, labels)\n",
    "pred_label = torch.argmax(logits,dim=-1)\n",
    "print(acc)\n",
    "\n",
    "g = to_nx_graph(batch_graph[0])\n",
    "print(true_labels,pred_label)\n",
    "\n",
    "nx.draw(g,pos=nx.circular_layout(g))\n",
    "plt.show()\n",
    "nx.draw(g)\n",
    "plt.show()\n",
    "nx.draw(g,pos=nx.circular_layout(g),node_color=weights[0][0].detach().numpy())\n",
    "plt.show()\n",
    "nx.draw(g,node_color=weights[0][0].detach().numpy())\n",
    "plt.show()\n",
    "nx.draw(g,pos=nx.circular_layout(g),node_color=weights[1][0].detach().numpy())\n",
    "plt.show()\n",
    "nx.draw(g,node_color=weights[1][0].detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[6] tree tree\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "0.0\n",
      "[6] tree circular_ladder\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "1.0\n",
      "[6] tree tree\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "1.0\n",
      "[6] tree tree\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[6] tree tree\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "0.0\n",
      "[6] tree barbell\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "1.0\n",
      "[6] tree tree\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "1.0\n",
      "[7] tri_lattice tri_lattice\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[6] tree tree\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[6] tree tree\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "0.0\n",
      "[3] cycle tree\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[6] tree tree\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[8] turan turan\n",
      "0.0\n",
      "[7] tri_lattice tree\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[2] complete complete\n",
      "0.0\n",
      "[5] shrinking_tree cycle\n",
      "1.0\n",
      "[6] tree tree\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "0.0\n",
      "[6] tree barbell\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[6] tree tree\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "0.0\n",
      "[1] circular_ladder cycle\n",
      "1.0\n",
      "[6] tree tree\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "1.0\n",
      "[6] tree tree\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "0.0\n",
      "[7] tri_lattice shrinking_tree\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "0.0\n",
      "[7] tri_lattice circular_ladder\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "1.0\n",
      "[6] tree tree\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[8] turan turan\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[8] turan turan\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "0.0\n",
      "[5] shrinking_tree tree\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "1.0\n",
      "[2] complete complete\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[6] tree tree\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "1.0\n",
      "[8] turan turan\n",
      "0.0\n",
      "[6] tree barbell\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "1.0\n",
      "[6] tree tree\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[8] turan turan\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[7] tri_lattice tri_lattice\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "1.0\n",
      "[2] complete complete\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "1.0\n",
      "[8] turan turan\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "0.0\n",
      "[6] tree circular_ladder\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[6] tree tree\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[6] tree tree\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "1.0\n",
      "[1] circular_ladder circular_ladder\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "1.0\n",
      "[6] tree tree\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "1.0\n",
      "[6] tree tree\n",
      "1.0\n",
      "[6] tree tree\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "1.0\n",
      "[7] tri_lattice tri_lattice\n",
      "0.0\n",
      "[6] tree barbell\n",
      "1.0\n",
      "[6] tree tree\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[2] complete complete\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "1.0\n",
      "[3] cycle cycle\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[8] turan turan\n",
      "1.0\n",
      "[0] barbell barbell\n",
      "0.0\n",
      "[7] tri_lattice turan\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n",
      "0.0\n",
      "[8] turan hypercube\n",
      "1.0\n",
      "[6] tree tree\n",
      "1.0\n",
      "[4] hypercube hypercube\n",
      "1.0\n",
      "[5] shrinking_tree shrinking_tree\n"
     ]
    }
   ],
   "source": [
    "#reset_cmd_args()\n",
    "model.eval()\n",
    "for _ in range(300):\n",
    "    index = np.random.choice(len(test_graphs))\n",
    "    batch_graph = [test_graphs[index]]\n",
    "    true_labels = [g.label for g in batch_graph]\n",
    "\n",
    "    node_feat, labels = myPrepareFeatureLabel(batch_graph)\n",
    "    embed,weights = myS2V_with_weight(model.s2v,batch_graph, node_feat, None)\n",
    "    logits, loss, acc =  model.mlp(embed, labels)\n",
    "    pred_label = torch.argmax(logits,dim=-1)\n",
    "    print(acc)\n",
    "\n",
    "    g = to_nx_graph(batch_graph[0])\n",
    "    print(true_labels,pred_label)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    nx.draw(g,pos=nx.circular_layout(g))\n",
    "    plt.savefig('./visualize/pictures/%d-%d-1.png'%(index,int(acc+0.5)))\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    nx.draw(g)\n",
    "    plt.savefig('./visualize/pictures/%d-%d-2.png'%(index,int(acc+0.5)))\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    nx.draw(g,pos=nx.circular_layout(g),node_color=weights[0][0].detach().numpy())\n",
    "    plt.savefig('./visualize/pictures/%d-%d-3.png'%(index,int(acc+0.5)))\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    nx.draw(g,node_color=weights[0][0].detach().numpy())\n",
    "    plt.savefig('./visualize/pictures/%d-%d-4.png'%(index,int(acc+0.5)))\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    nx.draw(g,pos=nx.circular_layout(g),node_color=weights[1][0].detach().numpy())\n",
    "    plt.savefig('./visualize/pictures/%d-%d-5.png'%(index,int(acc+0.5)))\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    nx.draw(g,node_color=weights[1][0].detach().numpy())\n",
    "    plt.savefig('./visualize/pictures/%d-%d-6.png'%(index,int(acc+0.5)))\n",
    "    #plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1, 26)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights),len(weights[0]),len(weights[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
